{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dd7ebb",
   "metadata": {},
   "source": [
    "# Project 3: Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d1891",
   "metadata": {},
   "source": [
    "### Analyze the output of an off-the-shelf NER model on scientific literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e04ce",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781f30b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2mg6lmc</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Transmissible Viral Vaccines</td>\n",
       "      <td>Genetic engineering now enables the design of ...</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acfwtc7t</td>\n",
       "      <td>PMC</td>\n",
       "      <td>CCR5 knockout suppresses experimental autoimmu...</td>\n",
       "      <td>Multiple sclerosis (MS) is an inflammatory dis...</td>\n",
       "      <td>2016-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47336zqs</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Dipeptidyl Peptidase 4 Distribution in the Hum...</td>\n",
       "      <td>Dipeptidyl peptidase 4 (DPP4, CD26), a type II...</td>\n",
       "      <td>2016-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c02v47jz</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Predicting Infectious Disease Using Deep Learn...</td>\n",
       "      <td>Infectious disease occurs when a person is inf...</td>\n",
       "      <td>2018-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rb8wg8k5</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Membrane Fusion and Cell Entry of XMRV Are pH-...</td>\n",
       "      <td>Xenotropic murine leukemia virus-related virus...</td>\n",
       "      <td>2012-03-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid  source_x                                              title  \\\n",
       "0  b2mg6lmc  Elsevier                       Transmissible Viral Vaccines   \n",
       "1  acfwtc7t       PMC  CCR5 knockout suppresses experimental autoimmu...   \n",
       "2  47336zqs  Elsevier  Dipeptidyl Peptidase 4 Distribution in the Hum...   \n",
       "3  c02v47jz       PMC  Predicting Infectious Disease Using Deep Learn...   \n",
       "4  rb8wg8k5       PMC  Membrane Fusion and Cell Entry of XMRV Are pH-...   \n",
       "\n",
       "                                            abstract publish_time  \n",
       "0  Genetic engineering now enables the design of ...   2018-01-31  \n",
       "1  Multiple sclerosis (MS) is an inflammatory dis...   2016-03-15  \n",
       "2  Dipeptidyl peptidase 4 (DPP4, CD26), a type II...   2016-01-31  \n",
       "3  Infectious disease occurs when a person is inf...   2018-07-27  \n",
       "4  Xenotropic murine leukemia virus-related virus...   2012-03-27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cord = pd.read_csv('data/cord19_sample/sample.csv')\n",
    "\n",
    "display(cord.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fe7813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8309"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of papers\n",
    "len(cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b26dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PMC         5097\n",
       "Elsevier    2696\n",
       "medrxiv      208\n",
       "WHO          157\n",
       "biorxiv      138\n",
       "CZI           13\n",
       "Name: source_x, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of papers by source\n",
    "cord['source_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0500dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest publication date: 1963-05-01 00:00:00\n",
      "Latest publication date: 2020-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# earliest and latest papers published time\n",
    "# convert 'publish_time' to datetime type\n",
    "cord['publish_time'] = pd.to_datetime(cord['publish_time'], errors='coerce')\n",
    "earliest = cord['publish_time'].min()\n",
    "latest = cord['publish_time'].max()\n",
    "\n",
    "print('Earliest publication date:', earliest)\n",
    "print('Latest publication date:', latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1154aa1",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57337209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "cord['document'] = cord.title + \" \" + cord.abstract\n",
    "# load a spacy model trained on web document\n",
    "nlp_web = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ner_results = []\n",
    "\n",
    "for text in cord['document']:\n",
    "    doc = nlp_web(text)\n",
    "    ner_results.append([(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "\n",
    "cord['ner_results'] = ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e3defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities from the document1:\n",
      "ORG Viral Vaccines Genetic\n"
     ]
    }
   ],
   "source": [
    "# try printing result of document1\n",
    "print('Entities from the document1:')\n",
    "for ent_text, ent_start, ent_end, ent_label in cord['ner_results'][0]:\n",
    "    print(ent_label, ent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddd0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities from the document2:\n",
      "PERSON myelin\n",
      "CARDINAL 5\n",
      "ORG CNS\n",
      "ORG CCR5\n",
      "ORG MS\n",
      "GPE CCR5\n",
      "PERSON myelin oligodendrocyte\n",
      "CARDINAL 35\n",
      "ORG EAE\n",
      "DATE 28 days\n",
      "ORG EAE\n",
      "ORG CD4(+\n",
      "ORG IL-1Î²\n",
      "ORG TNF\n",
      "ORG IFN\n",
      "ORG MCP-1\n",
      "PERSON Myelin\n",
      "ORG MBP\n",
      "GPE CNPase\n",
      "PRODUCT O4\n",
      "ORG CCR5\n",
      "ORG MS\n"
     ]
    }
   ],
   "source": [
    "# try printing result of document 2\n",
    "print('Entities from the document2:')\n",
    "for ent_text, ent_start, ent_end, ent_label in cord['ner_results'][1]:\n",
    "    print(ent_label, ent_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed8fea",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64ba300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average entities per document trained on web text: 15.045733541942472\n",
      "Average entities per type per document:\n",
      "label\n",
      "CARDINAL       3.428812\n",
      "DATE           1.364424\n",
      "EVENT          0.014201\n",
      "FAC            0.058130\n",
      "GPE            1.337947\n",
      "LANGUAGE       0.007702\n",
      "LAW            0.044289\n",
      "LOC            0.216272\n",
      "MONEY          0.026718\n",
      "NORP           0.496329\n",
      "ORDINAL        0.233361\n",
      "ORG            5.235407\n",
      "PERCENT        0.929594\n",
      "PERSON         1.095679\n",
      "PRODUCT        0.395836\n",
      "QUANTITY       0.076062\n",
      "TIME           0.037790\n",
      "WORK_OF_ART    0.047178\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_entities_per_document = cord['ner_results'].apply(len).mean()\n",
    "\n",
    "# calculate the average number of entities of each type per document\n",
    "all_entities = [entity for entities in cord['ner_results'] for entity in entities]\n",
    "entities_df = pd.DataFrame(all_entities, columns=['text', 'start', 'end', 'label'])\n",
    "avg_entities_per_type = entities_df.groupby('label').size() / len(cord)\n",
    "\n",
    "print('Average entities per document trained on web text:', avg_entities_per_document)\n",
    "print('Average entities per type per document:')\n",
    "print(avg_entities_per_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46090c28",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806ea6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common span for each entity type:\n",
      "label\n",
      "CARDINAL                  two\n",
      "DATE                     2019\n",
      "EVENT                   GDVII\n",
      "FAC             Mycobacterium\n",
      "GPE                     China\n",
      "LANGUAGE              English\n",
      "LAW                       HeV\n",
      "LOC               Middle East\n",
      "MONEY          18F-FDG PET/CT\n",
      "NORP                  Chinese\n",
      "ORDINAL                 first\n",
      "ORG                       RNA\n",
      "PERCENT                   95%\n",
      "PERSON            Escherichia\n",
      "PRODUCT                    S1\n",
      "QUANTITY             3500 ppm\n",
      "TIME                 24 hours\n",
      "WORK_OF_ART               SeV\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_common_spans = entities_df.groupby('label')['text'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "print('Most common span for each entity type:')\n",
    "print(most_common_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde9bc1",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f53b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\spacy\\language.py:2141: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# load a spacy model trained on scientific text\n",
    "nlp_sci = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "ner_results = []\n",
    "\n",
    "for text in cord['document']:\n",
    "    doc = nlp_sci(text)\n",
    "    ner_results.append([(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "\n",
    "cord['ner_results'] = ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f202a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities from the document2:\n",
      "ENTITY CCR5\n",
      "ENTITY knockout\n",
      "ENTITY suppresses\n",
      "ENTITY experimental autoimmune encephalomyelitis\n",
      "ENTITY C57BL/6 mice\n",
      "ENTITY Multiple sclerosis\n",
      "ENTITY MS\n",
      "ENTITY inflammatory disease\n",
      "ENTITY myelin\n",
      "ENTITY spinal cord\n",
      "ENTITY damaged\n",
      "ENTITY C-C chemokine receptor type 5\n",
      "ENTITY CCR5\n",
      "ENTITY immune cell\n",
      "ENTITY cytokine release\n",
      "ENTITY central nervous system\n",
      "ENTITY CNS\n",
      "ENTITY investigated\n",
      "ENTITY CCR5\n",
      "ENTITY MS\n",
      "ENTITY progression\n",
      "ENTITY murine\n",
      "ENTITY model\n",
      "ENTITY experimental autoimmune encephalomyelitis\n",
      "ENTITY EAE\n",
      "ENTITY CCR5\n",
      "ENTITY deficient\n",
      "ENTITY CCR5(â/â\n",
      "ENTITY CCR5(â/â\n",
      "ENTITY CCR5(+/+)\n",
      "ENTITY immunized\n",
      "ENTITY myelin oligodendrocyte glycoprotein\n",
      "ENTITY MOG(35\n",
      "ENTITY pertussis toxin\n",
      "ENTITY EAE\n",
      "ENTITY paralysis\n",
      "ENTITY scored\n",
      "ENTITY days\n",
      "ENTITY clinical scoring\n",
      "ENTITY EAE\n",
      "ENTITY neuropathology\n",
      "ENTITY CCR5(â/â)\n",
      "ENTITY CCR5(+/+)\n",
      "ENTITY Immune cells\n",
      "ENTITY CD3(+\n",
      "ENTITY CD4(+)\n",
      "ENTITY CD8(+)\n",
      "ENTITY B cell\n",
      "ENTITY NK cell\n",
      "ENTITY macrophages\n",
      "ENTITY infiltration\n",
      "ENTITY astrocytes/microglial activation\n",
      "ENTITY attenuated\n",
      "ENTITY CCR5(â/â)\n",
      "ENTITY levels\n",
      "ENTITY IL-1Î²\n",
      "ENTITY TNF-Î±\n",
      "ENTITY IFN-Î³\n",
      "ENTITY MCP-1\n",
      "ENTITY cytokine levels\n",
      "ENTITY decreased\n",
      "ENTITY CCR5(â/â)\n",
      "ENTITY spinal cord\n",
      "ENTITY Myelin basic protein\n",
      "ENTITY MBP\n",
      "ENTITY CNPase\n",
      "ENTITY increased\n",
      "ENTITY NG2\n",
      "ENTITY decreased\n",
      "ENTITY CCR5(â/â)\n",
      "ENTITY demyelination\n",
      "ENTITY suppressed\n",
      "ENTITY CCR5 gene\n",
      "ENTITY findings\n",
      "ENTITY CCR5\n",
      "ENTITY participating\n",
      "ENTITY demyelination\n",
      "ENTITY spinal cord\n",
      "ENTITY MS\n",
      "ENTITY development\n",
      "ENTITY therapeutic\n",
      "ENTITY target\n",
      "ENTITY treatment\n",
      "ENTITY MS\n"
     ]
    }
   ],
   "source": [
    "# try printing result of document 2\n",
    "print('Entities from the document2:')\n",
    "for ent_text, ent_start, ent_end, ent_label in cord['ner_results'][1]:\n",
    "    print(ent_label, ent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f698dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average entities per document trained on science text: 69.8979419906126\n",
      "Average entities per type per document:\n",
      "label\n",
      "ENTITY    69.897942\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_entities_per_document = cord['ner_results'].apply(len).mean()\n",
    "\n",
    "# calculate the average number of entities of each type per document\n",
    "all_entities = [entity for entities in cord['ner_results'] for entity in entities]\n",
    "entities_df = pd.DataFrame(all_entities, columns=['text', 'start', 'end', 'label'])\n",
    "avg_entities_per_type = entities_df.groupby('label').size() / len(cord)\n",
    "\n",
    "print('Average entities per document trained on science text:', avg_entities_per_document)\n",
    "print('Average entities per type per document:')\n",
    "print(avg_entities_per_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191dd1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common span for each entity type:\n",
      "label\n",
      "ENTITY    patients\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "most_common_spans = entities_df.groupby('label')['text'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "print('Most common span for each entity type:')\n",
    "print(most_common_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e4cc1",
   "metadata": {},
   "source": [
    "In the result when using the spaCy model trained on web text, entities are fit into several label categories, but in in the result when using the spaCy model trained on scientific text, all the entities haven't be recongnized as specific entity types by the model. This might because that in scientific texts, entities may be more specialized and diverse, and they may not fit into the general categories defined by spaCy's standard models trained on web text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter entities containing the substring 'covid' (case-insensitive)\n",
    "covid_entities = entities_df[entities_df['text'].str.lower().str.contains('covid')]\n",
    "\n",
    "# output unique spans\n",
    "unique_covid_spans = covid_entities['text'].unique()\n",
    "\n",
    "print('Unique entity spans containing \"covid\":')\n",
    "print(unique_covid_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f1a8d",
   "metadata": {},
   "source": [
    "The spans do not correspond to a single entity but rather represent various aspects, contexts, and references related to COVID-19. \n",
    "\n",
    "My outputs from this search may not sufficiently identify all papers from the dataset that are about \"COVID-19\". Though the extracted spans do capture a wide range of references to COVID-19, it's important to note that NER might not be perfect, and variations in terminology can exist, precision may vary, and some false positives might be present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c761ba",
   "metadata": {},
   "source": [
    "## Train a custom model for named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8daa6117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14987, 3466, 3684)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "train = ConllCorpusReader('data/conll2003/', 'eng.train', ['words', 'pos', 'ignore', 'chunk'])\n",
    "testa = ConllCorpusReader('data/conll2003/', 'eng.testa', ['words', 'pos', 'ignore', 'chunk'])\n",
    "testb = ConllCorpusReader('data/conll2003/', 'eng.testb', ['words', 'pos', 'ignore', 'chunk'])\n",
    "\n",
    "train_sents = list(train.iob_sents())\n",
    "testa_sents = list(testa.iob_sents())\n",
    "testb_sents = list(testb.iob_sents())\n",
    "\n",
    "len(train_sents), len(testa_sents), len(testb_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097c796",
   "metadata": {},
   "source": [
    "There are 14987 sentences in train split, 3466 sentences in testa split, 3684 sentences in testb split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c8bd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.586508307199573, 0, 113)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "train_each_length = [len(i) for i in train_sents]\n",
    "mean_train = sum(train_each_length) / len(train_sents)\n",
    "min_train = min(train_each_length)\n",
    "max_train = max(train_each_length)\n",
    "mean_train, min_train, max_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ab6abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.818811309867282, 0, 109)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testa\n",
    "testa_each_length = [len(i) for i in testa_sents]\n",
    "mean_testa = sum(testa_each_length) / len(testa_sents)\n",
    "min_testa = min(testa_each_length)\n",
    "max_testa = max(testa_each_length)\n",
    "mean_testa, min_testa, max_testa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186f2f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.604505971769816, 0, 124)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testb\n",
    "testb_each_length = [len(i) for i in testb_sents]\n",
    "mean_testb = sum(testb_each_length) / len(testb_sents)\n",
    "min_testb = min(testb_each_length)\n",
    "max_testb = max(testb_each_length)\n",
    "mean_testb, min_testb, max_testb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20e81e",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f75d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of NER labels in the train:\n",
      "O         169578\n",
      "I-PER      11128\n",
      "I-ORG      10001\n",
      "I-LOC       8286\n",
      "I-MISC      4556\n",
      "B-MISC        37\n",
      "B-ORG         24\n",
      "B-LOC         11\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Distribution of NER labels in the testA:\n",
      "O         42759\n",
      "I-PER      3149\n",
      "I-LOC      2094\n",
      "I-ORG      2092\n",
      "I-MISC     1264\n",
      "B-MISC        4\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Distribution of NER labels in the testB:\n",
      "O         38323\n",
      "I-PER      2773\n",
      "I-ORG      2491\n",
      "I-LOC      1919\n",
      "I-MISC      909\n",
      "B-MISC        9\n",
      "B-LOC         6\n",
      "B-ORG         5\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# flatten the list of sentences to get a list of (word, pos, label) tuples\n",
    "train_flat = [item for sublist in train_sents for item in sublist]\n",
    "testa_flat = [item for sublist in testa_sents for item in sublist]\n",
    "testb_flat = [item for sublist in testb_sents for item in sublist]\n",
    "\n",
    "# create df for each split\n",
    "df_train = pd.DataFrame(train_flat, columns=['word', 'pos', 'label'])\n",
    "df_testa = pd.DataFrame(testa_flat, columns=['word', 'pos', 'label'])\n",
    "df_testb = pd.DataFrame(testb_flat, columns=['word', 'pos', 'label'])\n",
    "\n",
    "print(\"Distribution of NER labels in the train:\")\n",
    "print(df_train['label'].value_counts())\n",
    "print()\n",
    "print(\"Distribution of NER labels in the testA:\")\n",
    "print(df_testa['label'].value_counts())\n",
    "print()\n",
    "print(\"Distribution of NER labels in the testB:\")\n",
    "print(df_testb['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b72a14",
   "metadata": {},
   "source": [
    "The label set and counts indicate a typical distribution for NER, where \"O\" represents entities that are outside the scope of interest, and other labels like \"I-PER,\" \"I-ORG,\" \"I-LOC,\" and \"I-MISC\" represent entities of a person, organization, location, and miscellaneous types, respectively. The counts for \"O\" are significantly higher, which is expected as non-entity tokens typically outnumber named entities in natural language text. The presence of \"B-MISC,\" \"B-ORG,\" \"B-LOC\" indicates the beginning of miscellaneous, organization, and location entities, respectively, although their counts are relatively low. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4540d",
   "metadata": {},
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54be325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading word2vec vectors\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aae3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|ââââââââââââââââââââââââââââââââââââââââ| 11989/11989 [01:48<00:00, 110.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1190\n",
      "Seconds required: 3.945\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.000000\n",
      "c2: 1.000000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=2.94  loss=197000.80 active=1190  feature_norm=5.00\n",
      "Iter 2   time=1.02  loss=142541.34 active=1190  feature_norm=3.93\n",
      "Iter 3   time=1.82  loss=105312.52 active=1190  feature_norm=3.30\n",
      "Iter 4   time=0.88  loss=98207.90 active=1190  feature_norm=3.76\n",
      "Iter 5   time=0.93  loss=83527.91 active=1190  feature_norm=4.63\n",
      "Iter 6   time=0.88  loss=62752.43 active=1190  feature_norm=7.50\n",
      "Iter 7   time=0.89  loss=50199.92 active=1190  feature_norm=10.23\n",
      "Iter 8   time=0.88  loss=40446.73 active=1190  feature_norm=14.30\n",
      "Iter 9   time=0.88  loss=36636.79 active=1190  feature_norm=16.78\n",
      "Iter 10  time=0.87  loss=33214.67 active=1190  feature_norm=20.03\n",
      "Iter 11  time=0.88  loss=31213.91 active=1190  feature_norm=23.31\n",
      "Iter 12  time=0.89  loss=30342.96 active=1190  feature_norm=26.20\n",
      "Iter 13  time=0.88  loss=29747.92 active=1190  feature_norm=26.57\n",
      "Iter 14  time=0.88  loss=29310.52 active=1190  feature_norm=27.17\n",
      "Iter 15  time=0.88  loss=29000.48 active=1190  feature_norm=27.49\n",
      "Iter 16  time=0.88  loss=28665.60 active=1190  feature_norm=27.75\n",
      "Iter 17  time=0.88  loss=28433.27 active=1190  feature_norm=27.53\n",
      "Iter 18  time=0.89  loss=28260.54 active=1190  feature_norm=27.19\n",
      "Iter 19  time=0.88  loss=28021.25 active=1190  feature_norm=26.98\n",
      "Iter 20  time=0.88  loss=27876.75 active=1190  feature_norm=27.47\n",
      "Iter 21  time=0.89  loss=27644.99 active=1190  feature_norm=27.77\n",
      "Iter 22  time=0.88  loss=27543.40 active=1190  feature_norm=28.27\n",
      "Iter 23  time=0.88  loss=27389.10 active=1190  feature_norm=29.31\n",
      "Iter 24  time=1.77  loss=27333.21 active=1190  feature_norm=29.88\n",
      "Iter 25  time=0.89  loss=27227.07 active=1190  feature_norm=30.76\n",
      "Iter 26  time=0.90  loss=27154.59 active=1190  feature_norm=31.32\n",
      "Iter 27  time=0.89  loss=27090.12 active=1190  feature_norm=31.68\n",
      "Iter 28  time=0.88  loss=27017.52 active=1190  feature_norm=32.03\n",
      "Iter 29  time=0.89  loss=27001.98 active=1190  feature_norm=32.18\n",
      "Iter 30  time=0.89  loss=26891.75 active=1190  feature_norm=32.47\n",
      "Iter 31  time=0.87  loss=26858.34 active=1190  feature_norm=32.49\n",
      "Iter 32  time=0.91  loss=26820.16 active=1190  feature_norm=32.57\n",
      "Iter 33  time=0.89  loss=26771.85 active=1190  feature_norm=32.80\n",
      "Iter 34  time=0.88  loss=26716.44 active=1190  feature_norm=33.11\n",
      "Iter 35  time=0.89  loss=26681.54 active=1190  feature_norm=33.24\n",
      "Iter 36  time=0.88  loss=26632.43 active=1190  feature_norm=33.49\n",
      "Iter 37  time=0.89  loss=26600.62 active=1190  feature_norm=33.73\n",
      "Iter 38  time=0.90  loss=26571.40 active=1190  feature_norm=33.98\n",
      "Iter 39  time=0.89  loss=26555.45 active=1190  feature_norm=33.98\n",
      "Iter 40  time=0.91  loss=26538.83 active=1190  feature_norm=34.02\n",
      "Iter 41  time=0.90  loss=26526.44 active=1190  feature_norm=34.08\n",
      "Iter 42  time=0.90  loss=26511.85 active=1190  feature_norm=34.26\n",
      "Iter 43  time=0.90  loss=26502.99 active=1190  feature_norm=34.40\n",
      "Iter 44  time=0.92  loss=26497.28 active=1190  feature_norm=34.38\n",
      "Iter 45  time=0.89  loss=26489.00 active=1190  feature_norm=34.42\n",
      "Iter 46  time=0.89  loss=26483.81 active=1190  feature_norm=34.48\n",
      "Iter 47  time=0.91  loss=26472.07 active=1190  feature_norm=34.60\n",
      "Iter 48  time=1.74  loss=26466.21 active=1190  feature_norm=34.71\n",
      "Iter 49  time=0.90  loss=26458.93 active=1190  feature_norm=34.75\n",
      "Iter 50  time=0.92  loss=26451.22 active=1190  feature_norm=34.78\n",
      "Iter 51  time=0.88  loss=26446.17 active=1190  feature_norm=34.82\n",
      "Iter 52  time=0.90  loss=26440.87 active=1190  feature_norm=34.82\n",
      "Iter 53  time=0.88  loss=26436.28 active=1190  feature_norm=34.83\n",
      "Iter 54  time=0.89  loss=26428.45 active=1190  feature_norm=34.85\n",
      "Iter 55  time=0.89  loss=26422.68 active=1190  feature_norm=34.91\n",
      "Iter 56  time=0.88  loss=26417.34 active=1190  feature_norm=34.93\n",
      "Iter 57  time=0.89  loss=26413.30 active=1190  feature_norm=34.95\n",
      "Iter 58  time=0.93  loss=26409.09 active=1190  feature_norm=34.97\n",
      "Iter 59  time=0.88  loss=26406.68 active=1190  feature_norm=35.00\n",
      "Iter 60  time=0.88  loss=26403.75 active=1190  feature_norm=34.99\n",
      "Iter 61  time=0.90  loss=26401.65 active=1190  feature_norm=34.98\n",
      "Iter 62  time=0.89  loss=26399.79 active=1190  feature_norm=34.98\n",
      "Iter 63  time=0.90  loss=26395.60 active=1190  feature_norm=34.99\n",
      "Iter 64  time=0.90  loss=26394.99 active=1190  feature_norm=35.04\n",
      "Iter 65  time=0.89  loss=26389.72 active=1190  feature_norm=35.01\n",
      "Iter 66  time=0.94  loss=26387.59 active=1190  feature_norm=35.00\n",
      "Iter 67  time=0.89  loss=26385.46 active=1190  feature_norm=34.98\n",
      "Iter 68  time=0.90  loss=26383.03 active=1190  feature_norm=34.96\n",
      "Iter 69  time=0.89  loss=26381.38 active=1190  feature_norm=34.96\n",
      "Iter 70  time=0.96  loss=26379.53 active=1190  feature_norm=34.97\n",
      "Iter 71  time=0.92  loss=26378.40 active=1190  feature_norm=34.97\n",
      "Iter 72  time=0.88  loss=26377.04 active=1190  feature_norm=34.98\n",
      "Iter 73  time=0.89  loss=26375.18 active=1190  feature_norm=34.99\n",
      "Iter 74  time=0.89  loss=26373.29 active=1190  feature_norm=35.01\n",
      "Iter 75  time=0.88  loss=26372.10 active=1190  feature_norm=35.01\n",
      "Iter 76  time=0.88  loss=26370.87 active=1190  feature_norm=35.01\n",
      "Iter 77  time=0.87  loss=26369.74 active=1190  feature_norm=35.02\n",
      "Iter 78  time=0.89  loss=26368.41 active=1190  feature_norm=35.02\n",
      "Iter 79  time=0.91  loss=26367.58 active=1190  feature_norm=35.02\n",
      "Iter 80  time=1.04  loss=26366.73 active=1190  feature_norm=35.03\n",
      "Iter 81  time=2.26  loss=26366.39 active=1190  feature_norm=35.04\n",
      "Iter 82  time=1.05  loss=26365.90 active=1190  feature_norm=35.05\n",
      "Iter 83  time=0.99  loss=26365.17 active=1190  feature_norm=35.06\n",
      "Iter 84  time=0.95  loss=26364.19 active=1190  feature_norm=35.08\n",
      "Iter 85  time=0.94  loss=26363.65 active=1190  feature_norm=35.11\n",
      "Iter 86  time=0.97  loss=26363.05 active=1190  feature_norm=35.11\n",
      "Iter 87  time=1.03  loss=26362.69 active=1190  feature_norm=35.11\n",
      "Iter 88  time=0.94  loss=26362.03 active=1190  feature_norm=35.13\n",
      "Iter 89  time=1.82  loss=26361.71 active=1190  feature_norm=35.15\n",
      "Iter 90  time=0.99  loss=26361.18 active=1190  feature_norm=35.18\n",
      "Iter 91  time=0.95  loss=26360.91 active=1190  feature_norm=35.19\n",
      "Iter 92  time=0.91  loss=26360.55 active=1190  feature_norm=35.21\n",
      "Iter 93  time=0.94  loss=26360.10 active=1190  feature_norm=35.24\n",
      "Iter 94  time=0.98  loss=26359.64 active=1190  feature_norm=35.29\n",
      "Iter 95  time=0.93  loss=26359.11 active=1190  feature_norm=35.32\n",
      "Iter 96  time=0.90  loss=26358.74 active=1190  feature_norm=35.32\n",
      "Iter 97  time=0.91  loss=26358.35 active=1190  feature_norm=35.34\n",
      "Iter 98  time=0.90  loss=26358.11 active=1190  feature_norm=35.36\n",
      "Iter 99  time=0.89  loss=26357.93 active=1190  feature_norm=35.36\n",
      "Iter 100 time=0.91  loss=26357.80 active=1190  feature_norm=35.36\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 97.514\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1190 (1190)\n",
      "Number of active attributes: 273 (300)\n",
      "Number of active labels: 8 (8)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.006\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CRF' object has no attribute 'keep_tempfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:973\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    970\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 973\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:614\u001b[0m, in \u001b[0;36mBaseEstimator._repr_mimebundle_\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;124;03m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     output \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m}\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiagram\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    616\u001b[0m         output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m estimator_html_repr(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:279\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[0;32m    272\u001b[0m pp \u001b[38;5;241m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[0;32m    273\u001b[0m     compact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    275\u001b[0m     indent_at_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m     n_max_elements_to_show\u001b[38;5;241m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[0;32m    277\u001b[0m )\n\u001b[1;32m--> 279\u001b[0m repr_ \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[0;32m    282\u001b[0m n_nonblank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(repr_\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:153\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m    152\u001b[0m     sio \u001b[38;5;241m=\u001b[39m _StringIO()\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:170\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width \u001b[38;5;241m-\u001b[39m indent \u001b[38;5;241m-\u001b[39m allowance\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rep) \u001b[38;5;241m>\u001b[39m max_width:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:431\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, level):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28mrepr\u001b[39m, readable, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m readable:\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:189\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, maxlevels, level):\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_repr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanged_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_changed_only\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    438\u001b[0m recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_only:\n\u001b[1;32m--> 440\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43m_changed_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:93\u001b[0m, in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_changed_params\u001b[39m(estimator):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124;03m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     init_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m     95\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init_func)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    208\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 210\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    212\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CRF' object has no attribute 'keep_tempfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    701\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    703\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    704\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    705\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    706\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 707\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[0;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m callable(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:279\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[0;32m    272\u001b[0m pp \u001b[38;5;241m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[0;32m    273\u001b[0m     compact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    275\u001b[0m     indent_at_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m     n_max_elements_to_show\u001b[38;5;241m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[0;32m    277\u001b[0m )\n\u001b[1;32m--> 279\u001b[0m repr_ \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[0;32m    282\u001b[0m n_nonblank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(repr_\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:153\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m    152\u001b[0m     sio \u001b[38;5;241m=\u001b[39m _StringIO()\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:170\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width \u001b[38;5;241m-\u001b[39m indent \u001b[38;5;241m-\u001b[39m allowance\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rep) \u001b[38;5;241m>\u001b[39m max_width:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pprint.py:431\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, level):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28mrepr\u001b[39m, readable, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m readable:\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:189\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, maxlevels, level):\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_repr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanged_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_changed_only\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    438\u001b[0m recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_only:\n\u001b[1;32m--> 440\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43m_changed_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py:93\u001b[0m, in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_changed_params\u001b[39m(estimator):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124;03m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     init_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m     95\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init_func)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    208\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 210\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    212\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# function to convert Word2Vec vectors to features\n",
    "def word_to_features(word: str) -> dict:\n",
    "    features = {}\n",
    "    if word in w2v_vectors:\n",
    "        word_vector = w2v_vectors[word]\n",
    "        for i, value in enumerate(w2v_vectors[word]):\n",
    "            features[f'w2v_{i}'] = float(value)\n",
    "    else:\n",
    "        for i in range(300):  # assuming Word2Vec vectors are 300-dimensional\n",
    "            features[f'w2v_{i}'] = 0.0\n",
    "    return features\n",
    "\n",
    "# function to convert a CONLL instance to a sequence of features associated with each word\n",
    "def sent_to_features(sent: list) -> list:\n",
    "    return [word_to_features(word) for word, pos, label in sent]\n",
    "\n",
    "def sent_to_labels(sent: list) -> list:\n",
    "    return [label for word, pos, label in sent]\n",
    "\n",
    "train,test = train_test_split(train_sents,test_size=0.2, random_state = 498)\n",
    "\n",
    "# convert train and test splits to features and labels\n",
    "X_train = [sent_to_features(sent) for sent in train]\n",
    "y_train = [sent_to_labels(sent) for sent in train]\n",
    "\n",
    "X_test = [sent_to_features(sent) for sent in test]\n",
    "y_test = [sent_to_labels(sent) for sent in test]\n",
    "\n",
    "# train CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b2dea",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df185110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-ORG       0.70      0.65      0.67      2092\n",
      "       I-PER       0.91      0.85      0.88      3149\n",
      "       I-LOC       0.82      0.81      0.81      2094\n",
      "      I-MISC       0.81      0.63      0.71      1264\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "      B-MISC       0.00      0.00      0.00         4\n",
      "       B-LOC       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.82      0.76      0.79      8603\n",
      "   macro avg       0.46      0.42      0.44      8603\n",
      "weighted avg       0.82      0.76      0.79      8603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X_testa = [sent_to_features(sent) for sent in testa_sents]\n",
    "y_testa = [sent_to_labels(sent) for sent in testa_sents]\n",
    "\n",
    "# remove O label when compute metrics (since most tokens are O)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "y_pred = crf.predict(X_testa)\n",
    "\n",
    "print(metrics.classification_report(flatten(y_testa), flatten(y_pred), labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e8a64",
   "metadata": {},
   "source": [
    "### 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76965146",
   "metadata": {},
   "source": [
    "From the result, there are notable differences between micro- and macro-averaged results. The micro-averaged results suggest that, overall, the model performs relatively better when considering all instances equally, regardless of the class.\n",
    "The macro-averaged results indicate that the model's performance is more varied across different classes, and the lower scores in macro-averaging might be influenced by classes with fewer instances. The differences between these two metrics highlight the impact of class imbalances on the overall evaluation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70e53d",
   "metadata": {},
   "source": [
    "### 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81917c0",
   "metadata": {},
   "source": [
    "From the result, we can see that classes B-ORG, B-MISC, B-LOC have have a precision, recall, and F1-score of 0.00, indicating that they were not predicted at all. This could be due to a lack of instances of these classes in the testA data (there are no B-ORG and B-LOC classes in testA and only 4 instances of B-MISC). This could be addressed by adjusting the feature representation, providing more examples of these cases in the training and testing data, or modifying the model architecture to better capture the structure of these entities. In addition, while precision for I-MISC has improved, recall has decreased. This might be due to that there are less instances in I-MISC than other classes start with \"I\". Augmenting the training data with more diverse examples of I-MISC or experimenting with different features could help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03df4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6430c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
